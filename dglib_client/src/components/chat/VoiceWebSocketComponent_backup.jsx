import React, { useState, useRef, useEffect } from 'react';
import SockJS from 'sockjs-client';
import { v4 as uuidv4 } from 'uuid';
import { Client } from '@stomp/stompjs';
import { API_SERVER_HOST, API_ENDPOINTS } from '../../api/config';


const sockJsUrl = `${API_SERVER_HOST}${API_ENDPOINTS.chatbot}/voice`;

const VoiceWebSocketComponent = ({ onClose }) => {
    const [isConnected, setIsConnected] = useState(false);
    const [serverMessages, setServerMessages] = useState([]); 
    const [isRecording, setIsRecording] = useState(false);
    // const [clientId, setClientId] = useRecoilState(clientIdState); 
    const [isUserSpeaking, setIsUserSpeaking] = useState(false);
    const prevSpeakingRef = useRef(false);
    const [isProcessing, setIsProcessing] = useState(false);

   
    const clientRef = useRef({ 
        stompClient: null,
        uuid: uuidv4(),
    });

    const audioRef = useRef({
        audioContext: null,
        stream: null,
        workletNode: null,
    });

    const stopRecording = () => {
        if (!isRecording && !audioRef.current.stream) return;
        
        audioRef.current.stream?.getTracks().forEach(track => track.stop());
        audioRef.current.audioContext?.close().catch(e => console.error("AudioContext close error:", e));

        audioRef.current.stream = null;
        audioRef.current.audioContext = null;
        audioRef.current.workletNode = null;
        
        setIsRecording(false);
        console.log("ğŸ¤ ë…¹ìŒ ì¤‘ì§€ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ");
    };

   
    const sendMessage = (type, body = {}) => {
        if (clientRef.current.stompClient?.active) {
            clientRef.current.stompClient.publish({
                destination: '/app/voice',
                body: JSON.stringify({
                    type: type,
                    
                    uuid: clientRef.current.uuid,
                    ...body
                }),
            });
        }
    };

    const startRecordingAndStreaming = async () => {
        if (isRecording) return;

        try {
            const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 48000 });
            audioRef.current.audioContext = audioContext;

            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioRef.current.stream = stream;
            
            await audioContext.audioWorklet.addModule('/audio-processor.js');

            const source = audioContext.createMediaStreamSource(stream);
            const workletNode = new AudioWorkletNode(audioContext, 'audio-processor', {
                processorOptions: {
                    sourceSampleRate: audioContext.sampleRate,
                    targetSampleRate: 16000, 
                    bufferSize: 4096, 
                }
            });
            audioRef.current.workletNode = workletNode;

            workletNode.port.onmessage = (event) => {
                if (isProcessing) {
                    return;
                }
                const pcm16Data = new Int16Array(event.data);
                if (pcm16Data.length > 0 && clientRef.current.stompClient?.active) {
                    const base64Data = btoa(String.fromCharCode.apply(null, new Uint8Array(pcm16Data.buffer)));
                    sendMessage('audio_chunk', { audioData: base64Data });
                }
            };
            
            source.connect(workletNode).connect(audioContext.destination); 
            
            setIsRecording(true);
            console.log("ğŸ¤ ì›ì‹œ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ë…¹ìŒ ë° ì „ì†¡ ì‹œì‘");

        } catch (error) {
            console.error("ë§ˆì´í¬ ë˜ëŠ” ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜:", error);
            alert("ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•˜ê±°ë‚˜ ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
            handleClose(); 
        }
    };
    
  
    useEffect(() => {
        if (clientRef.current.stompClient) return;
        
        console.log("STOMP ì—°ê²° ì‹œë„...");
        const stompClient = new Client({
            webSocketFactory: () => new SockJS(sockJsUrl),
            // debug: (str) => { console.log(new Date(), str); },
            reconnectDelay: 5000,
        });

        stompClient.onConnect = () => {
            console.log("âœ… STOMP ì—°ê²° ì„±ê³µ!");
            setIsConnected(true);
            
            const destination = `/topic/response/${clientRef.current.uuid}`;
            
            stompClient.subscribe(destination, (message) => {
                const receivedData = JSON.parse(message.body);
                console.log("ğŸ“© ì„œë²„ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ :", receivedData);
                
              
                if (receivedData.type === 'transcription_result' && receivedData.text) {
                    setServerMessages(prev => [...prev, { type: 'stt', text: receivedData.text }]);
                    setIsProcessing(false);
                    prevSpeakingRef.current = false;
                }
                if (receivedData.type === 'speaking_status') {
                    const newSpeakingState = receivedData.is_speaking;

                    if (newSpeakingState === false && prevSpeakingRef.current === true) {
                        setIsProcessing(true);
                        console.log("ì¼í•´ë¼ ê¿ˆí‹€ì•„");
                    }

                    setIsUserSpeaking(receivedData.is_speaking);
                    
                    prevSpeakingRef.current = newSpeakingState;
                }

                if (receivedData.type === 'no_speech_detected') {
                    console.log("ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë…¹ìŒì„ ì¤‘ì§€í•©ë‹ˆë‹¤.");
                    setIsUserSpeaking(false);
                    setIsProcessing(false);
                }




               
            });

          
            sendMessage('start_session');
            startRecordingAndStreaming();
        };

        stompClient.onStompError = (frame) => {
            console.error("ğŸ”¥ STOMP í”„ë¡œí† ì½œ ì˜¤ë¥˜:", frame.headers['message']);
            setIsConnected(false);
        };
        
        clientRef.current.stompClient = stompClient;
        stompClient.activate();

        // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬ í•¨ìˆ˜
        return () => {
            console.log("ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸. ì •ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.");
            handleClose(true); // isUnmounting í”Œë˜ê·¸ë¥¼ trueë¡œ ì „ë‹¬
        };
    
    }, []); 

    const handleClose = (isUnmounting = false) => {
        stopRecording();
        
        if (clientRef.current.stompClient?.active) {
            console.log("ì„¸ì…˜ ì¢…ë£Œ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.");
            sendMessage('end_session');
            
            // ì–¸ë§ˆìš´íŠ¸ ì‹œ ì¦‰ì‹œ ë¹„í™œì„±í™”, ì‚¬ìš©ì í´ë¦­ ì‹œ ì•½ê°„ì˜ ë”œë ˆì´ í›„ ë¹„í™œì„±í™”
            setTimeout(() => {
                
                const currentStompClient = clientRef.current.stompClient;
                if (currentStompClient && currentStompClient.active) {
                    console.log("STOMP ì—°ê²°ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.");
                    currentStompClient.deactivate();
                }
                clientRef.current.stompClient = null;
            }, isUnmounting ? 0 : 500);
        } else {
            clientRef.current.stompClient = null;
        }
        
        if (!isUnmounting) {
            onClose();
        }
    };
    
    return (
        <div className="fixed inset-0 bg-black/50 z-[200] flex items-center justify-center">
            <div className="bg-white rounded-lg p-6 max-w-md w-full mx-4">
                <div className="flex justify-between items-center mb-4">
                    <h3 className="text-lg font-semibold">ìŒì„± ëŒ€í™”</h3>
                    <button onClick={() => handleClose(false)} className="text-gray-500 hover:text-gray-700">
                        âœ•
                    </button>
                </div>
                <img src={`${isProcessing ? '/gumtle.gif' : '/gumtle1.png'}`} className="w-50 mx-auto" alt="gumtle"/>
                
                <div className="h-20 overflow-y-auto p-2 border rounded-md my-4 bg-gray-50">
                    {serverMessages.map((msg, index) => (
                        <p key={index} className="text-gray-700">{msg.text}</p>
                    ))}
                </div>
                {isConnected ? (
                    <div className="mb-3 mt-10 flex justify-center">
                        <div className="px-3 sm:px-4 py-2 rounded-lg bg-white text-gray-800 rounded-bl-none shadow">
                            <div className="flex items-center space-x-1">
                                <span className="text-sm mr-2">ê¶ê¸ˆí•œê²Œ ìˆìŒë©´ ë­ë“  ë¬¼ì–´ë´!</span>
                                <div className={`w-2 h-2 rounded-full bg-green-500 ${isUserSpeaking ? 'animate-bounce' : ''}`}></div>
                                <div className={`w-2 h-2 rounded-full bg-green-500 ${isUserSpeaking ? 'animate-bounce' : ''}`} style={{animationDelay: '0.15s'}}></div>
                                <div className={`w-2 h-2 rounded-full bg-green-500 ${isUserSpeaking ? 'animate-bounce' : ''}`} style={{animationDelay: '0.3s'}}></div>
                            </div>
                        </div>
                    </div>
                ) : (
                    <div className="mb-3 mt-10 flex justify-center">
                        <div className="px-3 sm:px-4 py-2 rounded-lg bg-white text-gray-800 rounded-bl-none shadow">
                            <p className="text-sm text-gray-500">ì„œë²„ì— ì—°ê²° ì¤‘...</p>
                        </div>
                    </div>
                )}
            </div>
        </div>
    );
};

export default VoiceWebSocketComponent;